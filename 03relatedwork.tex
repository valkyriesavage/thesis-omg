\chapter{Related Work}

\begin{quote}
If I have seen further, it is only by standing upon the shoulders of giants.

--- Isaac Newton
\end{quote}

Situating this thesis in the realm of prior work, we draw heavily on work from four major traditions: graphics and optimization, sensing, 3D modeling, and prototyping tools.

\subsection{Graphics/Optimization}

    The optimization community was one of the first to rally around digital fabrication: they have delved extensively into digital simulation of materials and behaviors, and the advent of hyper-precise 3D printers like the Objet Connex line allowed for a variety of real-world manifestations of these simulations.
    
    Mathematical optimization for structural analysis existed before digital fabrication, e.g. \cite{fleury-optimization}, and supported CNC machining. Some of the very earliest work on fabrication-related simulation focused on optimizing toolpaths, for example to ensure good coverage from robotic spray heads without occlusion from model features \cite{gursoz-noodles}. Other early work examined and accounted for deformities in models produced using different 3D printing technologies \cite{brown-simulate,hsu-numerical}, or ensuring printability of 3D models \cite{barequet-gaps,bohn-shellclosure}. More recently, researchers have investigated modeling and fabrication of deformation behavior \cite{bickel-deformation}, as well as subsurface scattering \cite{hasan-subsurface} and subsurface reflectance \cite{weyrich-reflectance}. Precision fabrication machines allow for creating tiny structural elements that can contribute to an object's overall appearance \cite{lan-appearance}.
    
    Higher-level optimization strategies can yield models with voids inside to ensure balance after fabrication \cite{prevost-makeitstand}, or musical instruments which have specific pitches after fabrication \cite{umetani-metallophone}. Another system can take motion capture sequences and translate them into fabricatable mechanical automata that perform the same motions \cite{ceylan-automata}.
    
    The actual fabrication process can also be improved with recent work in graphics. For example, linking knowledge of the layered manufacturing technique employed by FFF machines (described in Chapter 2) to a 3D model can help ensure that it will not break under force \cite{umetani-strength}, or that fabrication will produce minimal waste \cite{schmidt-support}. Properties of materials post-print can inform the design of automatically-inferred joints for poseable characters \cite{bacher-posable,cali-articulated}.
    
    This thesis will draw on the same theme of pre-fabrication simulation of materials and models. Certain types of sensing necessitate guaranteeing that a prototype will have specific material properties, however our focus does not end with the fabricated object itself. We use information from the model to inform our sensing techniques and to develop interactive prototypes.
    
\subsection{3D CAD Tools}
    Tools for 3D modeling are becoming more useful and usable as 3D printers become more accessible. Powerful industrial modeling tools, like SolidWorks \cite{solidworks}, AutoCAD \cite{autocad}, ProEngineer \cite{proe}, and Rhino \cite{rhino}, have existed for years and served industrial designers and professional engineers very well. However, research has investigated more accessible ways of modeling objects.
    
    Creating an object that fits with existing hardware (for example, with sensor modules to track user input) has been explored using Kinect-based scans of objects \emph{in situ} \cite{molyneaux-kinectfusion, weichel-mixfab} or photographs \cite{lau-modeling}, or intelligent capture of object dimensions with measuring tapes \cite{lee-handscape,weichel-spata}. Other work has explored tangible manipulation of building blocks \cite{anderson-tangible, gupta-duplotrack} or clay models \cite{savage-mmarks}. 3D models can even be created from sketches, by exploiting prior knowledge of post-fabrication material properties \cite{mori-plushie, saul-sketchchair}. Our work touches on 3D modeling, however we focus on augmenting existing 3D models with sensing rather than creating new ones from scratch.
    
    Other research explores capturing a designer's toolpath and creating a model and/or final artifact by automatically tidying it up \cite{willis-interactive, mueller-constructable, mueller-laserorigami}, or conversely \emph{directing} a toolpath using information from a 3D model and enabling a dialogue between user, tool, and model \cite{zoran-freed}. Once a designer creates an initial model, other tools allow modifying it tangibly, for example by letting the user sketch modifications on a printed version \cite{song-modelcraft-tochi}. We similarly link object geometry to its physical form, however we pursue this link for sensing purposes rather than for form finding.
    
    Sensing modules can be the primary driver of an object's form factor, for example by allowing designers to drag the modules around digitally and re-forming a shape that will hold them all \cite{weichel-mixfab}. This technique could be useful as an addon for our tools, but we focus on sensing rather than authoring 3D case forms. Pipe structures for joining sensors to microcontroller boards can allow for additional flexibility in design \cite{savage-sot}, however this requires that the designer has intimate knowledge of the sensing techniques to be used. Our tools build in knowledge of the sensing paradigm, relieving that burden from designers and allowing additional redesign flexibility versus one-off, hand-created sensor routings \cite{navarrette-gps, park-microchannels}.
    
    \cite{lau-converting} converting 3d furniture models to fabricatable parts and connectors
    
    \cite{schmidt-meshmixer} meshmixer!

\subsection{Sensing Techniques}

    \valkyrie{not all of these are for fabbed objects, but a slightly broader swath of sensing techniques definitely needs to be discussed here. segmenting into fabbed vs. not doesn't really draw a bright line of any kind, though, so... how to structure this part?}
    Research has likewise investigated a variety of ways for sensing digitally-fabricated devices, ranging from switches that close when a flexible object is bent \cite{slyper-structure} to audio frequencies swept through fabricated flutes \cite{laput-acoustruments}.

    \subsubsection{Using machine learning}
        Machine learning provides power and nuance to sensing tasks. By sweeping electrical frequencies through a conductive material (e.g., water), machine learning can detect if a user touches it with a finger versus with two fingers \cite{sato-touche}, or using audio in a similar way can detect palm versus fingertip interactions with objects \cite{ono-touchandactivate}. The acceleration profiles of scratching noises can be detected as gestures \cite{harrison-scratchinput}, and scratching noises along ridges can reveal whether a user is rubbing an object clockwise or counterclockwise \cite{murray-smith-stane}.
        
        Even more subtle interactions can be captured, for example by using continuous interpolation of signatures. This has been applied to sound swept through 3D printed flute-like tubes \cite{laput-acoustruments} to determine position continuously along sliders.
        
        However, employing machine learning requires training each gesture to be sensed. In addition, it requires training each \emph{combination} of gestures to be sensed, as swept sound or capacitance signatures may not combine linearly when gestures are performed contemporaneously. Our work eschews this complication: since we link geometry to sensing, we exploit this link to allow training-free sensing and/or improve our chances of sensing a user's interactions correctly.
    
    \subsubsection{Without machine learning}
        Other explorations have led to clever ways of avoiding the post-fabrication training necessary to use machine learning for sensing. For flexible objects, this can come in the form of internal switches designed to close when cast-silicone objects are manipulated in certain ways \cite{slyper-structure}, or as conductive material within microchannels whose resistance changes when stretched or bent \cite{majidi-curvature, park-microchannels}. Time-domain reflectometry, i.e., sending an electrical pulse through a wire and timing how long it takes to reflect back, can likewise detect user interaction with flexible objects \cite{wimmer-tdr}, as can adhesive sensing tape \cite{holman-tactiletape}. These techniques do not employ digital fabrication: they are hand-fabricated and -tuned. Because we digitally fabricate our artifacts, we can generate knowledge of geometry automatically. Digitally fabricated soft objects can have stretchable electronics embedded afterwards \cite{yao-pneui}, or be sensed using computer vision and barometric pressure \cite{harrison-buttons, slyper-pressure}; however, since these objects do not use knowledge of their interactive pieces, they cannot exploit the geometry-sensing link that we use for our work. Similarly, Olberding, et al., created a sensor that is maximally robust to post-fabrication user modification \cite{olberding-cuttable}. Again, this technique does not exploit the link between an object's geometry and its fabricated form to improve sensing.
        
        Identity can be embedded in objects' surface textures (intended for scratching) \cite{harrison-acoustic}; indeed identity can also be recorded in invisible chambers inside an object for later high-frequency imaging \cite{willis-infrastructs}. These projects use knowledge of the embedded identity tags to ``train'' their sensing, however they can only detect an object's identity and not how a user is interacting with it.
        
        Actual user interaction with digitally fabricated objects has been explored, as well, most notably by Willis, et al. Printed Optics allows for sensing fabricated mechanisms (like sliders and buttons) via light shining through tiny channels embedded in a print \cite{willis-printedoptics}. This work inspired our own, though Printed Optics does not offer a design tool or a way of providing this sensing without extensive hand-programming.

\subsection{Prototyping Tools}

    Our investigations in this thesis are ultimately looking at techniques for prototyping. There are many different types of prototypes: typically they are split into role, look-and-feel, and implementation \cite{houde-prototypes}. Within each of these types of prototype, there are opportunities to explore high-fidelity prototypes and low-fidelity prototypes. Our work seeks to help with high-fidelity look-and-feel and role prototypes; we recognize that our sensing techniques have some drawbacks as tools for final implementation (for example, the processing time required to recognize interactions using computer vision or audio).
    
    Other research has investigated easing this type of physical functionality exploration, often through the creation of toolkits that help users create interactive prototypes quickly. On the low-fidelity end, simple pushpins and copper tape can create circuitry for testing with cardboard mockups \cite{hudson-boxes}. Another simple solution is just sticking an accelerometer onto an object and using its output to inform interactions \cite{hook-making}. More sophisticated toolkits may include multi-purpose programmable microcontrollers \cite{arduino}, or even be designed for prototyping interactive devices on cloth \cite{buechley-lilypad}. Designers can have extra freedom with placing electronics when a board becomes a smart substrate that interlinks them automatically \cite{villar-voodooio}, or can use snap-together sensing and actuation modules \cite{avrahami-switcharoo, greenberg-phidgets, lee-calder} that could be programmed in a visual language \cite{villar-gadgeteer}. These techniques have several important limitations: most importantly, they \emph{constrain exploration}. If a user wishes to include a 3-inch slider in his design, but the kit only offers a 2-inch slider or a 5-inch slider, he has to make due. Our work's use of digital fabrication for sensor creation gives users this flexibility in design exploration, without tying them to pre-defined form factors.
    
    Circuitry, and thus any existing electronics, can be integrated directly into a 3D printed object by laying down conductive material \cite{sells-reprap,voxel8}, or by leaving voids to be filled with conductive material post-print \cite{savage-sot}; this still constrains designers to what already exists. Techniques like adding stick-on sensors or sensing tags \cite{maynes-aminzade-eyepatch,yeo-stickear} can mitigate this challenge, however they lead to one-off prototypes: with digital fabrication, designers can create a design, test it, then modify it digitally to create an improved design; they can even share it with coworkers without rebuilding it by hand each time.
    
    We also examine another important question: how is functionality defined in interactive prototypes? Software can be automated using screenshots as in Sikuli \cite{yeh-sikuli}, or perhaps with visual ``block''-based programming languages that are accessible to even children \cite{resnick-scratch}. Programming by demonstration can also aid novices in developing interactive applications with sensor components \cite{hartmann-dtools}, similarly functionality can be inferred from wireframe mockups of applications \cite{li-framewire}. To integrate hardware and software functionality, some researchers have explored augmented reality \cite{nam-AR} or projection \cite{akaoka-displayobjects} techniques to allow interactions to be defined only in code without functional hardware; recent online tools like 123D Circuits allow for simulating hardware and testing code for it without requiring the physical circuit be built \cite{123dcircuits}.
    

    \cite{nam-sketchingtuis} sketchingTUIs
    
    \cite{sarik-tracebrush} tracebrush
    
    \cite{macintyre-DART} DART
    
    \cite{klemmer-papiermache} papiermache
    
    \cite{fails-crayons} A Design Tool for Camera-based Interaction. video feeds and painting on the feeds to train a classifier for sensing.
    
    \cite{holman-sketchspace} sketchspace
    
    \cite{doering-composition} a thinking ``core'' put inside 3d printed ``shells''. this definitely needs to be discussed! though it is a WiP.
    
    \cite{hook-study}