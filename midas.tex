\chapter{Midas: Capacitive Sensing of Custom 2D Layouts}

\section{Preamble}

We begin our exploration of the interlink between sensing and geometry at the simple end of our spectra: Midas links 2D geometry, fabricated from conductive material, to capacitance sensing.

An increasing number of consumer products include user interfaces that rely on touch input. We describe Midas, a software and hardware toolkit to support the design, fabrication, and programming of flexible capacitive touch sensors for interactive objects. With Midas, designers first define the desired shape, layout, and type of touch sensitive areas, as well as routing obstacles, in a sensor editor. From this high-level specification, Midas automatically generates layout files with appropriate sensor pads and routed connections. These files are then used to fabricate sensors using digital fabrication processes, e.g., vinyl cutters and conductive ink printers. Using step-by-step assembly instructions generated by Midas, designers connect these sensors to the Midas microcontroller, which detects touch events. No training or initialization are necessary, as Midas performed the initial routing. Once the prototype is assembled, designers can define interactivity for their sensors: Midas supports both record-and-replay actions for controlling existing local applications and WebSocket-based event output for controlling novel or remote applications. In a first-use study with three participants, users successfully prototyped media players. We also demonstrate how Midas can be used to create a number of touch-sensitive interfaces.

\section{Introduction}

How is Midas related to other projects in thesis?

How are capacitive interfaces important?  How are they seen today?

\subsection{The Geometry-Sensing Link}

For the Midas project, we exploit the convenience of algorithmic routing. The designer creates a sensor layout which matches with her desired aesthetics and objects, then the machine performs the task of creating structures that allow the designer to detect user interactions with the sensors. This is convenient for the designer, as the task of laying out traces is hardly a glorious one. The layout is our link to sensing: the machine knows the routing, thus it has \emph{a priori} knowledge of what it will be sensing. When an interaction triggers a change in capacitance, Midas can connect this to the correct sensor.

\subsection{Users}

Our target users for Midas are designers who have 2D layout expertise, but who lack experience in electronics and possibly programming.  We target these types of designers through affordances familiar from graphic design programs, instruction-based assembly using a single hardware component, error detection/correction, and easy-to-use sensor output.

Midas echoes graphic and Graphical User Interface (GUI) design programs, offering designers a familiar drag-and-drop interface.  Midas also supports scaling via direct manipulation scaling, and has the ability to import custom sensor shapes as PNG images.

The instructions generated by Midas walk designers through machine setup, sensor fabrication, and microcontroller connection.  This instruction set assumes no knowledge about the machines, fabrication process, or electronics, and uses color-coded wiring to ensure circuit legibility.

In the case where setup goes awry, Midas can detect two common fault types by performing pattern recognition on its sensor inputs.  The faults are ``stuck on'', when sensor traces are too close together and are touching or capacitively coupled, and ``flicker'', when the microcontroller's connection to a sensor rapidly changes and indicates a poor attachment.

Midas's sensor output is available for interaction design via two channels: designers can record literal clicking and typing events on their screen that will be triggered by a sensor input (``record-and-replay''), or they may use JavaScript, a programming language with which many designers are familiar, to accept the events in the form of WebSockets messages for further processing in an interactive webpage.

All these usability features will be discussed in more detail in the implementation section, below.

\section{The Midas Toolkit}

In the following section we describe both a complete example of using the Midas toolkit for testing an interface design and the implementation of the toolkit's software and hardware components.

\subsection{Designing with Midas}

We discuss the interface affordances and the
workflow of Midas (Figure \ref{fig:designing}) with a concrete running example:
A designer would like to explore back-of-device and
bezel interactions for a mobile phone. In particular, she
would like to scroll through a list of emails with a slider on
the back of the device, and open, reply to, and delete messages
via sensors on the bezel under the phone user’s thumb.

\subsubsection{Drawing Sensors}
Users start by loading an image of the physical prototype
they want to augment into Midas’s sensor editor. The sensor
editor (Figure \ref{fig:editor}) allows a user to create the sensor layout, and
define interactive behavior for each sensor. The background
device image helps designers with correct scaling and positioning.
Currently, Midas supports 2D images, including
flattened 3D models. Future work will investigate direct support
of 3D models. Sensor positioning works analogously
to a GUI editor; users choose sensor types and drag them to the desired location on the canvas. Midas supports individual
discrete buttons, one-dimensional sliders, and two-dimensional
pads. Buttons can take on arbitrary shapes—
users can import any graphics file (in PNG format) or draw
custom polygons. Sliders and pads are currently restricted
to rectangular shapes; however, their size and aspect ratio
can be modified to fit the requirements of the prototype at
hand. Users may also define obstacles using the same drawing
tools to restrict routing -- Midas will route connections
around these obstacles.
In our phone example, the designer creates one slider and
three discrete buttons. For the buttons, she loads custom
shapes created in a drawing program. She defines a circular
obstacle around the phone’s camera so the camera will
not be obscured during connection routing.


\subsubsection{Fabricating and Applying Flexible Sensors}
Once users complete a layout, clicking the create stickers
button generates fabrication files. First, certain components
are automatically split into multiple sensing pads. For instance,
a slider can generate four interdigitated pads (Figure \ref{fig:templates}, third template) for continuous finger tracking, while
2D pads result in two separate layers of triangular pads (Figure
\ref{fig:2layer}). Second, Midas generates conductive traces that will
connect each of the pads to Midas’s touch controller. An additional mask file, to be fabricated in vinyl, includes cutouts
of only the sensor shapes: it will cover the traces both for aesthetic
reasons and to prevent stray touch events. Midas’s connection
routing determines the exact position of each touch
area. Should the user want to experiment with positioning,
Midas can also skip routing and only generate individual
touch pads. However, the user must then manually connect
wires to each sensor and register the sensor in the interface.

The pad creation and routing step generates a set of graphics
files (in SVG format) and an instruction sheet (in HTML)
which appears in the user’s browser (see Figure \ref{fig:instructions}). This sheet
contains step-by-step instructions describing how to fabricate
the generated files. For our implementation, instructions include
which SVG files to cut in which material and how to
transfer the cut designs to the prototype object.

In our phone example, the designer generates one SVG file
for the touch areas and one to mask the traces, which prevents
stray touch events. Following the generated instruction
web page, she feeds copper foil into her vinyl cutter and cuts
the corresponding SVG file. She then substitutes a vinyl roll
and cuts a mask layer. As both materials have adhesive backing,
she sticks the copper and vinyl layers onto the phone
she wishes to modify. Once the adhesive layers are applied,
she tapes the end of the routed traces to the Midas hardware,
which is plugged into her computer via USB. Since the design
files for her prototype are digital, she also sends them to
colleagues in another office for a second, remote test. With
the design files and a vinyl cutter, her colleagues can then
recreate a working Midas prototype.

\subsubsection{Connecting Hardware to Software}
Midas senses touch events with a dedicated touch controller
circuit board. Users do not have to program or assemble any
electronics--they may treat the entire setup as a prototyping
“dongle”. Users do have to connect the end of the traces to
the controller’s rainbow ribbon cable, either by taping the
cable leads onto copper traces or by soldering them.

To complete a prototype, users return to the sensor editor. In
many toolkits, mapping hardware components to named objects
in software can be error-prone—it is easy to swap wires
or connect to an incorrect pin. If the user prints a fully routed
design, Midas generates instructions for aligning touch areas
with specific ribbon cable colors. If the user decided to wire 
the design herself, this mapping has to be authored. Midas
uses guided demonstration to assist with this process. For
buttons, the user selects an input element in the UI and clicks
the tie to stickers button; next she touches the corresponding
copper sensor. Midas listens for status change events and
automatically assigns hardware pins. Midas registers sliders
similarly: users are asked to swipe a finger along the slider.

Midas’s editor interface displays incoming touch data visually,
re-coloring touched sensors in pink on the sensor editor,
to aid the user in debugging. If something goes wrong during
the connection stage, it is apparent to the user. Midas
also reads the data stream for common errors. If it detects
that two wires may be too close together and triggering each
other, or that there may be a faulty connection from a wire
to the board, that information is displayed to the user in a
connection status area.

\subsubsection{Adding Interactivity}
Designers have two options for authoring interactivity: record-and-replay
of mouse and keyboard events (a strategy adopted
from BOXES \ref{BOXES} and Exemplar \ref{Exemplar}), or touch event output
to control applications via WebSockets. To record and replay
interactions, designers select a sensor in the editor, then click
on the record interaction button. They can then control any
open application (e.g., start or stop a media player application,
or drag a volume slider). Midas records the generated
keyboard and mouse events and can replay them later in response
to touch input (Figure \ref{fig:recordreplay}).

The types of desktop UI actions that can be executed depend
on the button type. Individual buttons can be tied to an interaction
script, a sequence of keyboard and mouse events
recorded by the user. Sliders are linked to exactly one horizontal
or vertical line on the screen to be controlled by clicks
along its length. 2D pads can control a 2D area on the screen
analogous to a slider area. For sliders and pads, the user must
capture the location on the screen that she wishes to control
with the slider or pad. This is done by clicking at each end
of the slider or in opposite corners of the pad, guided by Midas
prompts. As the user adjusts the sensitivity (number of
discrete buttons) of the slider or pad to be printed, the interaction
with the captured on-screen slider or pad becomes
more fine-grained, also.

Record-and-replay does not require programming, but it is
brittle; changes in application layout or response latency can
break a recorded sequence. To let users author more robust
interactions, Midas uses WebSockets to send touch events
over the Internet. This requires programming, but WebSockets
enable designers to work in the languages many are most
familiar with: HTML and JavaScript.

In our phone example, the designer chooses WebSockets as
she wants to demonstrate how touch events can control a mobile
email application. She creates a mockup in HTML and
writes JavaScript functions to receive touch events.

\subsection{Implementation}

We describe the architecture and algorithms underlying the Midas toolkit's software and hardware.

\subsubsection{The Midas CAD tool}

We discuss the key parts of the Midas CAD tool: generating sensor pads, routing pads to the touch controller, and detecting .

\subsubsection{The Midas Hardware}

We discuss the several components of the Midas hardware: the mechanism of capacitive touch sensing and fabrication of compatible sensor pads.

\section{Evaluation}

\subsection{User Study}

\subsection{Design Examples}

\section{Discussion}

\subsection{Sweet Spots}

flat or ruled objects, or 3D objects that are ``unfoldable’’

testing and iterating on different kinds of interactions (e.g., back of device) : touch screens are good for I/O, but it's not necessary to put screens everywhere!

prototyping new device form factors (e.g., media player) -- user study

\subsection{Limitations}

no true 3d

no feedback (e.g., button depressing)